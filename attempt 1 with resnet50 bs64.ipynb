{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./car_data/\"\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_tfms)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 64, shuffle=True, num_workers = 2)\n",
    "\n",
    "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\n",
    "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 64, shuffle=False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            #inputs = inputs.to(device).half() # uncomment for half precision model\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/64*running_correct/len(trainloader)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data\n",
    "            #images = images.to(device).half() # uncomment for half precision model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# replace the last fc layer with an untrained one (requires grad by default)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 150 s, loss: 4.5193, acc: 9.6924\n",
      "Accuracy of the network on the test images: 27 %\n",
      "Epoch 2, duration: 101 s, loss: 2.2999, acc: 47.2290\n",
      "Accuracy of the network on the test images: 57 %\n",
      "Epoch 3, duration: 98 s, loss: 1.1142, acc: 74.5850\n",
      "Accuracy of the network on the test images: 68 %\n",
      "Epoch 4, duration: 99 s, loss: 0.6203, acc: 85.6689\n",
      "Accuracy of the network on the test images: 73 %\n",
      "Epoch 5, duration: 97 s, loss: 0.3758, acc: 91.6260\n",
      "Accuracy of the network on the test images: 80 %\n",
      "Epoch 6, duration: 99 s, loss: 0.2472, acc: 94.6289\n",
      "Accuracy of the network on the test images: 83 %\n",
      "Epoch 7, duration: 102 s, loss: 0.1368, acc: 97.1558\n",
      "Accuracy of the network on the test images: 89 %\n",
      "Epoch 8, duration: 100 s, loss: 0.1039, acc: 97.9858\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Epoch 9, duration: 99 s, loss: 0.0930, acc: 98.3398\n",
      "Accuracy of the network on the test images: 89 %\n",
      "Epoch 10, duration: 99 s, loss: 0.0904, acc: 98.2056\n",
      "Accuracy of the network on the test images: 89 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6a6ea819ec72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlrscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d457fb645c67>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#inputs = inputs.to(device).half() # uncomment for half precision model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
    "\n",
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
